graph [
  directed 1
  multigraph 1
  node [
    id 0
    label "NIST AI 100-1"
    type "document"
    description "NIST AI 100-1 is a publication that outlines the Artificial Intelligence Risk Management Framework (AI RMF 1.0), providing guidelines and standards for managing risks associated with AI systems throughout their lifecycle."
    community_id 0
  ]
  node [
    id 1
    label "Artificial Intelligence Risk Management Framework (AI RMF 1.0)"
    type "framework"
    description "A framework intended to manage risks associated with artificial intelligence, designed to be a living document that will be regularly updated."
    community_id 0
  ]
  node [
    id 2
    label "U.S. Department of Commerce"
    type "organization"
    description "A government department responsible for promoting economic growth, which oversees the National Institute of Standards and Technology."
    community_id 0
  ]
  node [
    id 3
    label "Gina M. Raimondo"
    type "person"
    description "The Secretary of the U.S. Department of Commerce."
    community_id 0
  ]
  node [
    id 4
    label "National Institute of Standards and Technology"
    type "organization"
    description "A federal agency that develops and promotes measurement standards, including those for artificial intelligence."
    community_id 0
  ]
  node [
    id 5
    label "Laurie E. Locascio"
    type "person"
    description "The Director of the National Institute of Standards and Technology and Under Secretary of Commerce for Standards and Technology."
    community_id 0
  ]
  node [
    id 6
    label "AI RMF Playbook"
    type "resource"
    description "A supplementary resource related to the AI RMF, providing additional guidance and tools for implementing the framework."
    community_id 5
  ]
  node [
    id 7
    label "NIST"
    type "organization"
    description "The National Institute of Standards and Technology (NIST) is a U.S. federal agency responsible for developing standards and guidelines for various technologies, including artificial intelligence."
    community_id 5
  ]
  node [
    id 8
    label "Version Control Table"
    type "tool"
    description "A tool used to track changes in documents, including version numbers, dates, and descriptions of changes."
    community_id 5
  ]
  node [
    id 9
    label "AI Risks and Trustworthiness"
    type "category"
    description "This category within the AI RMF Playbook addresses various aspects of AI risks and the criteria necessary for AI systems to be considered trustworthy."
    community_id 5
  ]
  node [
    id 10
    label "Foundational Information"
    type "section"
    description "A section in the AI RMF Playbook that provides essential background information on AI risk management."
    community_id 5
  ]
  node [
    id 11
    label "Core and Profiles"
    type "section"
    description "A section in the AI RMF Playbook that outlines the core components and profiles related to AI risk management."
    community_id 5
  ]
  node [
    id 12
    label "AI RMF 1.0"
    type "framework"
    description "The AI RMF 1.0 provides structured guidelines for managing risks associated with AI systems, emphasizing trustworthiness and effective risk management practices."
    community_id 5
  ]
  node [
    id 13
    label "AI RMF Core"
    type "system"
    description "The core component of the AI RMF that includes actions and outcomes to manage AI risks and develop trustworthy AI systems."
    community_id 1
  ]
  node [
    id 14
    label "Govern"
    type "function"
    description "The GOVERN function of the AI RMF focuses on establishing governance structures for AI systems and cultivating a culture of risk management within organizations."
    community_id 1
  ]
  node [
    id 15
    label "Map"
    type "function"
    description "The MAP function in the AI RMF involves identifying and assessing AI risks and their impacts, serving as a starting point for risk management processes."
    community_id 1
  ]
  node [
    id 16
    label "Measure"
    type "function"
    description "The MEASURE function within the AI RMF focuses on evaluating the effectiveness of risk management strategies and assessing AI risks and outcomes."
    community_id 1
  ]
  node [
    id 17
    label "Manage"
    type "function"
    description "The MANAGE function in the AI RMF deals with the ongoing management of identified risks throughout the AI system lifecycle, allocating resources as defined by governance structures."
    community_id 1
  ]
  node [
    id 18
    label "AI Risks"
    type "risk"
    description "AI risks refer to potential negative impacts and uncertainties associated with the deployment and use of AI systems, differing from traditional software risks."
    community_id 5
  ]
  node [
    id 19
    label "AI Actor Tasks"
    type "category"
    description "Tasks performed by various actors involved in the AI lifecycle, including testing, evaluation, verification, and validation."
    community_id 1
  ]
  node [
    id 20
    label "OECD Framework for the Classification of AI systems"
    type "standard"
    description "A framework developed by OECD for classifying AI systems, referenced in the context of AI lifecycle and dimensions."
    community_id 11
  ]
  node [
    id 21
    label "AI actors"
    type "person"
    description "AI actors are individuals or entities responsible for various aspects of the AI lifecycle, ensuring the integrity and performance of AI systems."
    community_id 1
  ]
  node [
    id 22
    label "trustworthy AI systems"
    type "system"
    description "AI systems characterized by necessary conditions of trustworthiness, including validity, reliability, accountability, and transparency."
    community_id 4
  ]
  node [
    id 23
    label "AI risk management activities"
    type "function"
    description "Functions that organize activities to govern, map, measure, and manage risks associated with AI technologies."
    community_id 20
  ]
  node [
    id 24
    label "NIST AI RMF 1.0"
    type "framework"
    description "The NIST AI RMF 1.0 is a framework designed to manage AI risks and guide organizations in the responsible use of AI technologies."
    community_id 2
  ]
  node [
    id 25
    label "AI technologies"
    type "technology"
    description "Technologies that have the potential to transform various sectors of society, including commerce, health, transportation, and cybersecurity."
    community_id 2
  ]
  node [
    id 26
    label "AI RMF"
    type "framework"
    description "The AI RMF is designed to help organizations manage risks associated with AI systems, promoting trustworthy development and use across various contexts."
    community_id 11
  ]
  node [
    id 27
    label "AI systems"
    type "technology"
    description "AI systems are technological solutions that utilize artificial intelligence to perform tasks typically requiring human intelligence, impacting individuals and society in various ways."
    community_id 9
  ]
  node [
    id 28
    label "OECD Recommendation on AI:2019"
    type "standard"
    description "A recommendation that provides guidelines for the responsible development and use of AI systems."
    community_id 11
  ]
  node [
    id 29
    label "ISO/IEC 22989:2022"
    type "standard"
    description "An international standard that addresses the characteristics and requirements of AI systems."
    community_id 11
  ]
  node [
    id 30
    label "AI risk management"
    type "practice"
    description "A practice focused on minimizing potential negative impacts of AI systems, including the need for human intervention in certain cases."
    community_id 10
  ]
  node [
    id 31
    label "societal dynamics"
    type "category"
    description "Factors related to human behavior and societal interactions that influence the deployment and functioning of AI systems."
    community_id 9
  ]
  node [
    id 32
    label "inequitable outcomes"
    type "outcome"
    description "Undesirable results that can be amplified or perpetuated by AI systems if not properly controlled."
    community_id 9
  ]
  node [
    id 33
    label "Responsible AI"
    type "framework"
    description "A framework that emphasizes human centricity, social responsibility, and sustainability in the design, development, and use of AI systems."
    community_id 10
  ]
  node [
    id 34
    label "ISO 26000:2010"
    type "standard"
    description "An international standard that outlines social responsibility and the impacts of organizational decisions on society and the environment."
    community_id 10
  ]
  node [
    id 35
    label "ISO/IEC TR 24368:2022"
    type "standard"
    description "A standard that defines professional responsibility in the context of AI, ensuring that professionals recognize their influence on society and the future of AI."
    community_id 10
  ]
  node [
    id 36
    label "National Artificial Intelligence Initiative Act of 2020"
    type "document"
    description "This legislative act directs the development and implementation of AI initiatives in the U.S., establishing frameworks for managing AI risks and promoting responsible AI development."
    community_id 11
  ]
  node [
    id 37
    label "National AI Initiative Act of 2020"
    type "document"
    description "A legislative act aimed at promoting and coordinating AI research and development efforts in the United States."
    community_id 2
  ]
  node [
    id 38
    label "National Security Commission on Artificial Intelligence"
    type "organization"
    description "This commission provides recommendations on advancing AI technology while ensuring national security."
    community_id 2
  ]
  node [
    id 39
    label "AI lifecycle"
    type "process"
    description "The stages through which an AI system progresses, from development to deployment, where contextual awareness can be enhanced."
    community_id 20
  ]
  node [
    id 40
    label "AI Risk Management Framework Roadmap"
    type "document"
    description "A roadmap that outlines priority research and guidance to enhance the AI RMF."
    community_id 5
  ]
  node [
    id 41
    label "ISO 31000:2018"
    type "standard"
    description "ISO 31000:2018 is an international standard that provides guidelines and principles for managing risks within organizations."
    community_id 13
  ]
  node [
    id 42
    label "risk management"
    type "function"
    description "Risk management involves coordinated activities to identify, assess, and mitigate risks within an organization, particularly focusing on minimizing negative impacts associated with AI systems."
    community_id 13
  ]
  node [
    id 43
    label "individuals, communities, and society"
    type "category"
    description "Stakeholders that can experience the impacts of AI systems, both positive and negative."
    community_id 13
  ]
  node [
    id 44
    label "third-party software, hardware, and data"
    type "resource"
    description "External resources that can influence the development and deployment of AI systems, potentially complicating risk measurement."
    community_id 9
  ]
  node [
    id 45
    label "risk measurement challenges"
    type "category"
    description "Challenges associated with quantifying and qualifying risks related to AI systems, particularly when risks are not well-defined."
    community_id 9
  ]
  node [
    id 46
    label "AI system"
    type "system"
    description "An AI system is a technological framework that employs artificial intelligence to perform tasks typically requiring human intelligence, ensuring safety, security, and responsible governance."
    community_id 10
  ]
  node [
    id 47
    label "risk metrics"
    type "category"
    description "Quantitative measures used to assess the risks associated with AI systems."
    community_id 10
  ]
  node [
    id 48
    label "methodologies"
    type "methodology"
    description "Structured approaches or techniques used to measure and manage risks in AI systems."
    community_id 3
  ]
  node [
    id 49
    label "third-party data"
    type "resource"
    description "Data sourced from external entities that can be integrated into AI products or services."
    community_id 23
  ]
  node [
    id 50
    label "emergent risks"
    type "risk"
    description "Newly arising risks that may not have been previously identified or considered in risk management efforts."
    community_id 24
  ]
  node [
    id 51
    label "reliable metrics"
    type "category"
    description "Metrics that are consistent, accurate, and trustworthy for measuring risk and trustworthiness in AI."
    community_id 25
  ]
  node [
    id 52
    label "impacts on a population"
    type "outcome"
    description "The effects or consequences that AI systems may have on different groups within a population."
    community_id 3
  ]
  node [
    id 53
    label "AI developer"
    type "person"
    description "An AI developer is an individual or organization that creates AI software and implements systems based on specific designs, considering associated risks."
    community_id 4
  ]
  node [
    id 54
    label "AI deployer"
    type "person"
    description "An AI deployer is responsible for implementing and operating AI models in real-world contexts, facing distinct risks compared to developers."
    community_id 4
  ]
  node [
    id 55
    label "trustworthy AI system"
    type "system"
    description "A trustworthy AI system is designed to be reliable and fit for purpose, ensuring that all AI actors share responsibilities in its development and deployment."
    community_id 20
  ]
  node [
    id 56
    label "inscrutability"
    type "risk"
    description "Inscrutability refers to the challenges in understanding and measuring risks associated with AI systems due to their opaque nature and lack of transparency."
    community_id 13
  ]
  node [
    id 57
    label "human baseline"
    type "category"
    description "Human baseline refers to the metrics used for comparison when assessing AI systems that augment or replace human activities, particularly in decision-making."
    community_id 13
  ]
  node [
    id 58
    label "Risk Tolerance"
    type "category"
    description "Risk tolerance reflects an organization's readiness to accept risks in pursuit of objectives, influenced by various contextual factors."
    community_id 5
  ]
  node [
    id 59
    label "ISO GUIDE 73"
    type "standard"
    description "ISO GUIDE 73 provides definitions and guidelines for risk management, including concepts like risk tolerance and residual risk."
    community_id 5
  ]
  node [
    id 60
    label "organizations"
    type "organization"
    description "Entities that are supported by the AI RMF to operate under applicable domestic and international legal or regulatory regimes."
    community_id 11
  ]
  node [
    id 61
    label "policies and norms"
    type "guideline"
    description "Established rules and standards that influence risk tolerances for AI systems."
    community_id 5
  ]
  node [
    id 62
    label "risk management framework"
    type "framework"
    description "A structured approach to identifying, assessing, and mitigating risks associated with AI."
    community_id 5
  ]
  node [
    id 63
    label "civil society"
    type "sector"
    description "A sector that contributes to the development and debate of methods for informing harm/cost-benefit tradeoffs in AI."
    community_id 26
  ]
  node [
    id 64
    label "risk management culture"
    type "category"
    description "A risk management culture refers to the organizational mindset that recognizes and addresses various AI risks, promoting purposeful allocation of resources."
    community_id 5
  ]
  node [
    id 65
    label "risk criteria"
    type "guideline"
    description "Risk criteria are established guidelines that help organizations assess and manage risks, including tolerance and response strategies."
    community_id 14
  ]
  node [
    id 66
    label "risk tolerance"
    type "standard"
    description "Risk tolerance is the level of risk that an organization is willing to accept while pursuing its objectives."
    community_id 14
  ]
  node [
    id 67
    label "residual risk"
    type "risk"
    description "Residual risk is the risk that remains after risk treatment has been applied, impacting end users and communities."
    community_id 5
  ]
  node [
    id 68
    label "end users"
    type "person"
    description "End users are individuals or communities that interact with AI systems, providing insights and feedback on their impacts and associated risks."
    community_id 10
  ]
  node [
    id 69
    label "cybersecurity"
    type "category"
    description "Cybersecurity encompasses the practices and technologies used to protect systems, networks, and data from cyber threats."
    community_id 20
  ]
  node [
    id 70
    label "privacy"
    type "characteristic"
    description "The protection of personal data, which can sometimes be at odds with the interpretability of AI systems."
    community_id 9
  ]
  node [
    id 71
    label "small to medium-sized organizations"
    type "organization"
    description "These organizations may face unique challenges in managing AI risks compared to larger organizations due to their limited resources and capabilities."
    community_id 20
  ]
  node [
    id 72
    label "large organizations"
    type "organization"
    description "Large organizations typically have more resources and capabilities to manage AI risks effectively compared to smaller counterparts."
    community_id 20
  ]
  node [
    id 73
    label "OECD"
    type "organization"
    description "The OECD (Organisation for Economic Co-operation and Development) has developed a framework for classifying AI lifecycle activities according to five key socio-technical dimensions relevant for AI policy and governance."
    community_id 1
  ]
  node [
    id 74
    label "TEVV processes"
    type "methodology"
    description "Test, evaluation, verification, and validation processes that ensure the effectiveness of AI systems."
    community_id 20
  ]
  node [
    id 75
    label "TEVV"
    type "function"
    description "TEVV refers to tasks that provide insights into technical, societal, legal, and ethical standards, assisting in risk management throughout the AI lifecycle."
    community_id 11
  ]
  node [
    id 76
    label "People &#38; Planet dimension"
    type "category"
    description "This dimension represents human rights and the broader well-being of society and the planet within the AI RMF context."
    community_id 1
  ]
  node [
    id 77
    label "Plan and Design function"
    type "function"
    description "A function performed throughout the AI system lifecycle, focusing on planning and designing AI applications."
    community_id 6
  ]
  node [
    id 78
    label "AI system lifecycle"
    type "system"
    description "The stages through which an AI system progresses, from conception to deployment and beyond."
    community_id 6
  ]
  node [
    id 79
    label "environmental groups"
    type "organization"
    description "Organizations focused on environmental issues that can provide context and understanding of AI impacts."
    community_id 10
  ]
  node [
    id 80
    label "civil society organizations"
    type "organization"
    description "Organizations that represent the interests of the public and can contribute to AI risk management."
    community_id 10
  ]
  node [
    id 81
    label "trustworthy AI"
    type "category"
    description "AI systems that are valid, reliable, safe, secure, resilient, accountable, transparent, explainable, interpretable, privacy-enhanced, and fair with harmful bias managed."
    community_id 5
  ]
  node [
    id 82
    label "AI trustworthiness characteristics"
    type "function"
    description "Characteristics that define the trustworthiness of AI systems, including accountability and transparency."
    community_id 7
  ]
  node [
    id 83
    label "social and organizational behavior"
    type "domain"
    description "The behaviors and practices within social and organizational contexts that influence AI trustworthiness."
    community_id 7
  ]
  node [
    id 84
    label "datasets"
    type "resource"
    description "Datasets are collections of data used to train AI systems, impacting their trustworthiness and relevance."
    community_id 7
  ]
  node [
    id 85
    label "AI models and algorithms"
    type "technology"
    description "The computational methods and structures that underpin AI systems and affect their trustworthiness."
    community_id 7
  ]
  node [
    id 86
    label "human judgment"
    type "function"
    description "The decision-making process employed by humans to determine metrics related to AI trustworthiness."
    community_id 7
  ]
  node [
    id 87
    label "AI trustworthiness"
    type "concept"
    description "A social concept that encompasses various characteristics of AI systems, emphasizing that trustworthiness is influenced by tradeoffs among these characteristics."
    community_id 11
  ]
  node [
    id 88
    label "interpretability"
    type "framework"
    description "Interpretability refers to the meaning of the outputs generated by AI systems in the context of their designed functional purposes."
    community_id 9
  ]
  node [
    id 89
    label "predictive accuracy"
    type "characteristic"
    description "The ability of an AI system to make correct predictions, which may be compromised in favor of interpretability."
    community_id 9
  ]
  node [
    id 90
    label "data sparsity"
    type "condition"
    description "A situation where there is insufficient data, which can lead to tradeoffs in AI system performance."
    community_id 9
  ]
  node [
    id 91
    label "TEVV findings"
    type "resource"
    description "Findings related to Trustworthiness, Explainability, Verifiability, and Validity that can be evaluated by subject matter experts."
    community_id 8
  ]
  node [
    id 92
    label "contextually sensitive evaluations"
    type "practice"
    description "Evaluations that take into account the specific context in which an AI system operates, aiming to identify benefits and risks."
    community_id 20
  ]
  node [
    id 93
    label "trustworthiness characteristics"
    type "category"
    description "Trustworthiness characteristics are attributes that determine the reliability, fairness, and transparency of AI systems."
    community_id 4
  ]
  node [
    id 94
    label "AI designer"
    type "person"
    description "An AI designer is an individual responsible for creating the design and specifications of an AI system."
    community_id 4
  ]
  node [
    id 95
    label "ISO 9000:2015"
    type "standard"
    description "ISO 9000:2015 is an international standard that specifies requirements for a quality management system."
    community_id 27
  ]
  node [
    id 96
    label "ISO/IEC TS 5723:2022"
    type "standard"
    description "ISO/IEC TS 5723:2022 defines reliability, accuracy, and safety requirements for AI systems, ensuring they do not endanger human life or the environment."
    community_id 9
  ]
  node [
    id 97
    label "AI technology"
    type "technology"
    description "AI technology includes tools and systems that utilize artificial intelligence to perform tasks typically requiring human intelligence."
    community_id 11
  ]
  node [
    id 98
    label "negative AI risks"
    type "risk"
    description "Negative AI risks refer to the potential adverse effects and consequences that arise from the deployment of AI systems."
    community_id 11
  ]
  node [
    id 99
    label "accuracy"
    type "function"
    description "The closeness of results of observations, computations, or estimates to the true values."
    community_id 9
  ]
  node [
    id 100
    label "robustness"
    type "function"
    description "The ability of a system to maintain its level of performance under a variety of circumstances."
    community_id 9
  ]
  node [
    id 101
    label "safety risks"
    type "risk"
    description "Safety risks associated with AI systems can lead to serious harm, necessitating tailored management approaches to ensure they remain within acceptable limits."
    community_id 10
  ]
  node [
    id 102
    label "NIST Cybersecurity Framework"
    type "framework"
    description "A framework that provides guidelines for managing cybersecurity risks, focusing on securing and resilient practices."
    community_id 11
  ]
  node [
    id 103
    label "NIST Risk Management Framework"
    type "framework"
    description "A framework that provides a structured process for managing risks associated with information systems."
    community_id 11
  ]
  node [
    id 104
    label "AI safety risk management approaches"
    type "category"
    description "Approaches that focus on managing risks associated with AI systems to ensure safety and reliability."
    community_id 11
  ]
  node [
    id 105
    label "security and resilience"
    type "category"
    description "Characteristics of AI systems that relate to their ability to withstand adverse events and maintain functionality."
    community_id 11
  ]
  node [
    id 106
    label "Resilience"
    type "concept"
    description "The ability to return to normal function after an unexpected adverse event, relating to robustness and the unexpected or adversarial use of data."
    community_id 12
  ]
  node [
    id 107
    label "Security"
    type "concept"
    description "Encompasses resilience and includes protocols to avoid, protect against, respond to, or recover from attacks."
    community_id 12
  ]
  node [
    id 108
    label "Accountability"
    type "concept"
    description "A characteristic of trustworthy AI that presupposes transparency."
    community_id 2
  ]
  node [
    id 109
    label "Transparency"
    type "concept"
    description "Transparency in AI refers to the availability of information regarding the system's operations and outputs, promoting fairness and accountability."
    community_id 2
  ]
  node [
    id 110
    label "transparency"
    type "category"
    description "Transparency in AI emphasizes clarity and openness about the mechanisms and processes involved in AI system operations."
    community_id 9
  ]
  node [
    id 111
    label "accountability"
    type "category"
    description "Accountability in the context of AI systems involves the responsibility of developers and deployers to ensure that the systems operate fairly and ethically."
    community_id 13
  ]
  node [
    id 112
    label "training data"
    type "resource"
    description "Training data refers to the datasets used to train AI systems, which can influence their performance and decision-making capabilities."
    community_id 9
  ]
  node [
    id 113
    label "explainability"
    type "framework"
    description "Explainability refers to the representation of the mechanisms underlying the operation of AI systems, helping users understand how decisions are made."
    community_id 9
  ]
  node [
    id 114
    label "Explainable AI"
    type "framework"
    description "A framework that focuses on making AI systems understandable to users by providing insights into their functionality and trustworthiness."
    community_id 2
  ]
  node [
    id 115
    label "Interpretability"
    type "category"
    description "A characteristic of AI systems that allows users to understand the meaning or context of decisions made by the system."
    community_id 2
  ]
  node [
    id 116
    label "NIST Privacy Framework"
    type "framework"
    description "A framework designed to help organizations manage privacy risks and enhance privacy protections."
    community_id 11
  ]
  node [
    id 117
    label "Privacy-enhancing technologies (PETs)"
    type "technology"
    description "Technologies designed to protect privacy in AI systems, including methods like de-identification and aggregation."
    community_id 11
  ]
  node [
    id 118
    label "Fairness in AI"
    type "framework"
    description "A concept that includes concerns for equality and equity, addressing issues such as harmful bias and discrimination in AI systems."
    community_id 5
  ]
  node [
    id 119
    label "Bias"
    type "risk"
    description "A broader concept than demographic balance and data representativeness, which can affect fairness in AI systems."
    community_id 5
  ]
  node [
    id 120
    label "NIST Special Publication 1270"
    type "document"
    description "NIST Special Publication 1270 provides guidance on identifying and managing bias in artificial intelligence."
    community_id 0
  ]
  node [
    id 121
    label "systemic bias"
    type "category"
    description "A type of bias that can be present in AI datasets and organizational practices, reflecting broader societal norms."
    community_id 5
  ]
  node [
    id 122
    label "computational and statistical bias"
    type "category"
    description "Biases that arise from systematic errors in AI datasets and algorithmic processes, often due to non-representative samples."
    community_id 5
  ]
  node [
    id 123
    label "human-cognitive bias"
    type "category"
    description "Biases related to individual or group perceptions of AI system information, influencing decision-making processes."
    community_id 5
  ]
  node [
    id 124
    label "fairness"
    type "concept"
    description "A principle that aims to ensure equitable treatment and outcomes in the context of AI systems."
    community_id 9
  ]
  node [
    id 125
    label "AI community"
    type "category"
    description "A collective term for organizations and individuals involved in the development and management of artificial intelligence technologies."
    community_id 5
  ]
  node [
    id 126
    label "TEVV practices"
    type "practice"
    description "Practices related to Testing, Evaluation, Validation, and Verification of AI systems."
    community_id 5
  ]
  node [
    id 127
    label "downstream risks"
    type "risk"
    description "Risks that arise as a consequence of AI system deployment and operation."
    community_id 1
  ]
  node [
    id 128
    label "diverse team"
    type "category"
    description "A team composed of individuals with varied backgrounds and perspectives contributing to AI development."
    community_id 1
  ]
  node [
    id 129
    label "NIST AI RMF Playbook"
    type "document"
    description "The NIST AI RMF Playbook outlines practices for governing and managing AI risks, including a framework for mapping and measuring AI system impacts."
    community_id 14
  ]
  node [
    id 130
    label "NIST Trustworthy and Responsible AI Resource Center"
    type "organization"
    description "A center that encompasses the AI RMF and the Playbook, focusing on promoting trustworthy and responsible AI practices."
    community_id 14
  ]
  node [
    id 131
    label "organizational culture"
    type "category"
    description "Organizational culture shapes how an organization operates and manages risk, reflecting shared values and beliefs."
    community_id 13
  ]
  node [
    id 132
    label "governing authorities"
    type "organization"
    description "Governing authorities are entities that establish policies and frameworks to guide an organization's mission, goals, and risk tolerance."
    community_id 13
  ]
  node [
    id 133
    label "senior leadership"
    type "person"
    description "Senior leadership refers to the top executives in an organization who set the tone for risk management and influence organizational culture."
    community_id 13
  ]
  node [
    id 134
    label "GOVERN function"
    type "function"
    description "The GOVERN function provides a framework for organizations to establish policies and processes for managing AI risks, clarifying roles and responsibilities within Human-AI team configurations."
    community_id 14
  ]
  node [
    id 135
    label "organizational risk priorities"
    type "category"
    description "The priorities set by an organization to manage risks associated with its operations, particularly in AI."
    community_id 14
  ]
  node [
    id 136
    label "AI risk management training"
    type "practice"
    description "Training provided to personnel and partners to equip them with the skills needed to manage AI risks effectively."
    community_id 14
  ]
  node [
    id 137
    label "executive leadership"
    type "person"
    description "The individuals in leadership positions within the organization responsible for decision-making regarding AI risks."
    community_id 14
  ]
  node [
    id 138
    label "GOVERN 5"
    type "document"
    description "A guideline that emphasizes the importance of robust engagement with relevant AI actors."
    community_id 1
  ]
  node [
    id 139
    label "GOVERN 5.1"
    type "document"
    description "A guideline detailing the need for organizational policies to collect and integrate feedback from external sources regarding AI risks."
    community_id 20
  ]
  node [
    id 140
    label "GOVERN 5.2"
    type "document"
    description "A guideline that establishes mechanisms for incorporating feedback from relevant AI actors into system design."
    community_id 15
  ]
  node [
    id 141
    label "GOVERN 6"
    type "document"
    description "A guideline that addresses AI risks and benefits arising from third-party software and data."
    community_id 16
  ]
  node [
    id 142
    label "GOVERN 6.1"
    type "document"
    description "A guideline focused on policies addressing AI risks associated with third-party entities."
    community_id 28
  ]
  node [
    id 143
    label "GOVERN 6.2"
    type "document"
    description "A guideline that outlines contingency processes for handling failures in high-risk third-party data or AI systems."
    community_id 17
  ]
  node [
    id 144
    label "MAP function"
    type "function"
    description "The MAP function establishes the context for AI systems, identifying risks and informing decision-making related to model management and safety."
    community_id 20
  ]
  node [
    id 145
    label "MEASURE function"
    type "function"
    description "The MEASURE function evaluates AI risks through objective assessments and analytical outputs, focusing on safety, security, and transparency."
    community_id 20
  ]
  node [
    id 146
    label "MANAGE function"
    type "function"
    description "The MANAGE function focuses on addressing and managing identified AI risks based on assessments from the MAP and MEASURE functions."
    community_id 20
  ]
  node [
    id 147
    label "internal team"
    type "organization"
    description "A diverse team within an organization that contributes to the development and deployment of AI systems."
    community_id 10
  ]
  node [
    id 148
    label "external collaborators"
    type "organization"
    description "Individuals or groups outside the internal team that engage with the team to provide perspectives on AI systems."
    community_id 10
  ]
  node [
    id 149
    label "potentially impacted communities"
    type "category"
    description "Groups of people who may be affected by the deployment and decisions of AI systems."
    community_id 10
  ]
  node [
    id 150
    label "Framework users"
    type "person"
    description "Framework users are individuals or organizations that utilize the NIST AI RMF to assess and manage risks associated with AI systems."
    community_id 20
  ]
  node [
    id 151
    label "organizational risk tolerances"
    type "risk"
    description "The levels of risk that an organization is willing to accept when deploying AI technologies."
    community_id 18
  ]
  node [
    id 152
    label "interdisciplinary AI actors"
    type "person"
    description "Individuals with diverse competencies and skills involved in the development and deployment of AI systems."
    community_id 18
  ]
  node [
    id 153
    label "scientific integrity"
    type "category"
    description "A category that encompasses the principles of maintaining accuracy and reliability in scientific research related to AI."
    community_id 20
  ]
  node [
    id 154
    label "TEVV considerations"
    type "category"
    description "Considerations related to Trustworthiness, Explainability, Verifiability, and Validity in the context of AI systems."
    community_id 20
  ]
  node [
    id 155
    label "organizational risk tolerance"
    type "category"
    description "The level of risk that an organization is willing to accept in pursuit of its objectives."
    community_id 20
  ]
  node [
    id 156
    label "AI system categorization"
    type "function"
    description "The classification of AI systems based on their capabilities and contexts."
    community_id 20
  ]
  node [
    id 157
    label "operator and practitioner proficiency"
    type "function"
    description "The skills and knowledge required for effective operation and trustworthiness of AI systems."
    community_id 19
  ]
  node [
    id 158
    label "third-party software and data"
    type "resource"
    description "External software and data sources that may be integrated into AI systems."
    community_id 11
  ]
  node [
    id 159
    label "internal risk controls"
    type "system"
    description "Measures and protocols established to manage and mitigate risks within AI systems."
    community_id 29
  ]
  node [
    id 160
    label "impacts to individuals, groups, communities, organizations, and society"
    type "outcome"
    description "The effects that AI systems may have on various stakeholders and societal structures."
    community_id 9
  ]
  node [
    id 161
    label "trustworthy characteristics"
    type "category"
    description "Trustworthy characteristics are attributes of AI systems that ensure their reliable and ethical operation."
    community_id 9
  ]
  node [
    id 162
    label "metrics and measurement methodologies"
    type "methodology"
    description "Approaches and techniques used to quantify and assess AI risks, ensuring adherence to scientific, legal, and ethical norms."
    community_id 20
  ]
  node [
    id 163
    label "system trustworthiness"
    type "outcome"
    description "The degree to which an AI system can be trusted based on its performance and risk assessment."
    community_id 20
  ]
  node [
    id 164
    label "risk monitoring and response efforts"
    type "action"
    description "Activities aimed at overseeing and addressing identified risks in AI systems."
    community_id 20
  ]
  node [
    id 165
    label "human subject protection"
    type "standard"
    description "Requirements that ensure the safety and rights of human subjects involved in evaluations."
    community_id 30
  ]
  node [
    id 166
    label "TEVV metrics"
    type "resource"
    description "Metrics and processes employed to evaluate the effectiveness of the MEASURE function in assessing AI systems."
    community_id 20
  ]
  node [
    id 167
    label "privacy risk"
    type "risk"
    description "Risks related to the privacy of data handled by AI systems, which are examined and documented."
    community_id 10
  ]
  node [
    id 168
    label "fairness and bias"
    type "risk"
    description "Concerns regarding the equitable treatment of individuals by AI systems, which are evaluated and documented."
    community_id 10
  ]
  node [
    id 169
    label "environmental impact"
    type "risk"
    description "The effects of AI model training and management activities on the environment, which are assessed and documented."
    community_id 10
  ]
  node [
    id 170
    label "domain experts"
    type "person"
    description "Individuals with specialized knowledge in a particular area relevant to AI risk assessment."
    community_id 20
  ]
  node [
    id 171
    label "affected communities"
    type "organization"
    description "Groups of people who may be impacted by the deployment of AI systems."
    community_id 20
  ]
  node [
    id 172
    label "AI risks"
    type "category"
    description "Risks associated with the deployment and operation of AI systems, which are prioritized and managed through the MANAGE function."
    community_id 20
  ]
  node [
    id 173
    label "negative residual risks"
    type "risk"
    description "The sum of all unmitigated risks that affect downstream acquirers of AI systems and end users."
    community_id 9
  ]
  node [
    id 174
    label "non-AI alternative systems"
    type "technology"
    description "Systems or approaches that do not utilize artificial intelligence but can serve as alternatives."
    community_id 20
  ]
  node [
    id 175
    label "MANAGE 3"
    type "function"
    description "A function focused on managing AI risks and benefits from third-party entities."
    community_id 0
  ]
  node [
    id 176
    label "MANAGE 3.1"
    type "subdivision"
    description "A subcategory that involves regular monitoring of AI risks and benefits from third-party resources."
    community_id 0
  ]
  node [
    id 177
    label "MANAGE 3.2"
    type "subdivision"
    description "A subcategory that focuses on monitoring pre-trained models used in AI system development."
    community_id 0
  ]
  node [
    id 178
    label "MANAGE 4"
    type "function"
    description "A function that documents and monitors risk treatments, including response and recovery plans for identified AI risks."
    community_id 0
  ]
  node [
    id 179
    label "MANAGE 4.1"
    type "subdivision"
    description "A subcategory that implements post-deployment monitoring plans for AI systems."
    community_id 0
  ]
  node [
    id 180
    label "MANAGE 4.2"
    type "subdivision"
    description "A subcategory that integrates measurable activities for continual improvements into AI system updates."
    community_id 0
  ]
  node [
    id 181
    label "MANAGE 4.3"
    type "subdivision"
    description "A subcategory that focuses on communication processes regarding incidents and errors to relevant AI actors."
    community_id 0
  ]
  node [
    id 182
    label "AI RMF Profiles"
    type "framework"
    description "AI RMF use-case profiles are implementations of the AI RMF functions, categories, and subcategories for specific settings or applications based on requirements, risk tolerance, and resources."
    community_id 0
  ]
  node [
    id 183
    label "AI RMF temporal profiles"
    type "framework"
    description "Descriptions of either the current state or the desired, target state of specific AI risk management activities within a given sector, industry, organization, or application context."
    community_id 0
  ]
  node [
    id 184
    label "Current Profile"
    type "document"
    description "Indicates how AI is currently being managed and the related risks in terms of current outcomes."
    community_id 21
  ]
  node [
    id 185
    label "Target Profile"
    type "document"
    description "Indicates the outcomes needed to achieve the desired or target AI risk management goals."
    community_id 21
  ]
  node [
    id 186
    label "AI Development"
    type "function"
    description "AI Development encompasses tasks performed during the AI Model phase of the lifecycle, focusing on model building and interpretation."
    community_id 1
  ]
  node [
    id 187
    label "AI Deployment"
    type "function"
    description "AI Deployment involves tasks performed during the Task and Output phase, ensuring the AI system is effectively used in production."
    community_id 1
  ]
  node [
    id 188
    label "Operation and Monitoring"
    type "function"
    description "Operation and Monitoring tasks are conducted in the Application Context/Operate and Monitor phase, focusing on assessing system output and impacts."
    community_id 1
  ]
  node [
    id 189
    label "Test, Evaluation, Verification, and Validation (TEVV)"
    type "framework"
    description "A framework encompassing tasks performed throughout the AI lifecycle to ensure the reliability and compliance of AI systems."
    community_id 9
  ]
  node [
    id 190
    label "compliance experts"
    type "person"
    description "Compliance experts are professionals who ensure AI systems adhere to legal, regulatory, and ethical standards during their operation and monitoring."
    community_id 9
  ]
  node [
    id 191
    label "Human Factors"
    type "category"
    description "Tasks and activities that focus on human-centered design and the integration of human dynamics in the AI lifecycle."
    community_id 20
  ]
  node [
    id 192
    label "organizational management"
    type "organization"
    description "Entities responsible for overseeing and managing the implementation and operation of AI systems within organizations."
    community_id 9
  ]
  node [
    id 193
    label "Human factors professionals"
    type "person"
    description "Professionals who provide multidisciplinary skills and perspectives to understand the context of use and engage in consultative processes related to AI system design."
    community_id 1
  ]
  node [
    id 194
    label "Domain Expert"
    type "person"
    description "Practitioners or scholars who provide knowledge or expertise in a specific industry or application area where an AI system is used."
    community_id 1
  ]
  node [
    id 195
    label "AI Impact Assessment"
    type "function"
    description "Tasks that involve assessing and evaluating requirements for AI system accountability and examining the impacts of AI systems."
    community_id 1
  ]
  node [
    id 196
    label "Procurement tasks"
    type "function"
    description "Tasks conducted by AI actors with authority for the acquisition of AI models, products, or services from third-party developers."
    community_id 1
  ]
  node [
    id 197
    label "Governance and Oversight tasks"
    type "function"
    description "Tasks assumed by AI actors with management and legal authority responsible for the organization in which an AI system is designed and deployed."
    community_id 1
  ]
  node [
    id 198
    label "Third-party entities"
    type "organization"
    description "Providers, developers, vendors, and evaluators of data, algorithms, models, and systems that are external to the organization acquiring their technologies or services."
    community_id 31
  ]
  node [
    id 199
    label "Affected individuals/communities"
    type "person"
    description "Individuals, groups, communities, or organizations directly or indirectly affected by AI systems or decisions based on their outputs."
    community_id 9
  ]
  node [
    id 200
    label "Other AI actors"
    type "organization"
    description "Entities that provide norms or guidance for specifying and managing AI risks, including trade associations, standards organizations, advocacy groups, and civil society organizations."
    community_id 20
  ]
  node [
    id 201
    label "General public"
    type "person"
    description "Individuals, communities, and consumers who directly experience the impacts of AI technologies and may motivate actions taken by AI actors."
    community_id 2
  ]
  node [
    id 202
    label "AI RMF 1"
    type "framework"
    description "The first version of the AI Risk Management Framework developed by NIST."
    community_id 0
  ]
  node [
    id 203
    label "AI-based technology"
    type "technology"
    description "Technologies that utilize artificial intelligence to perform tasks that typically require human intelligence."
    community_id 22
  ]
  node [
    id 204
    label "traditional software"
    type "category"
    description "Software systems that do not incorporate artificial intelligence and follow conventional programming paradigms."
    community_id 22
  ]
  node [
    id 205
    label "pre-trained models"
    type "resource"
    description "AI models that have been previously trained on a dataset and can be fine-tuned for specific tasks."
    community_id 9
  ]
  node [
    id 206
    label "transfer learning"
    type "methodology"
    description "Transfer learning is a machine learning technique that reuses a model developed for one task as the starting point for a model on a different task."
    community_id 9
  ]
  node [
    id 207
    label "data quality issues"
    type "risk"
    description "Problems related to the accuracy, completeness, and reliability of data used in AI systems, which can affect their trustworthiness."
    community_id 22
  ]
  node [
    id 208
    label "Privacy and cybersecurity risk management"
    type "practice"
    description "Approaches and considerations for managing privacy and cybersecurity risks in the context of AI system design and deployment."
    community_id 9
  ]
  node [
    id 209
    label "enterprise risk management"
    type "framework"
    description "A comprehensive approach to identifying, assessing, and managing risks across an organization, including those related to AI."
    community_id 9
  ]
  node [
    id 210
    label "Secure Software Development Framework"
    type "framework"
    description "A framework that outlines best practices for developing secure software to mitigate security risks."
    community_id 11
  ]
  node [
    id 211
    label "MAP, MEASURE, and MANAGE functions"
    type "function"
    description "Functions within the AI RMF that focus on managing and measuring risks associated with AI systems."
    community_id 11
  ]
  node [
    id 212
    label "harmful bias"
    type "risk"
    description "A risk associated with AI systems that leads to unfair or discriminatory outcomes."
    community_id 9
  ]
  node [
    id 213
    label "generative AI"
    type "technology"
    description "A type of AI that can generate new content or data based on learned patterns."
    community_id 9
  ]
  node [
    id 214
    label "machine learning attacks"
    type "risk"
    description "Security threats that exploit vulnerabilities in machine learning models."
    community_id 9
  ]
  node [
    id 215
    label "third-party AI technologies"
    type "resource"
    description "AI technologies developed by external organizations that may pose risks when integrated into an organization's systems."
    community_id 9
  ]
  node [
    id 216
    label "human roles and responsibilities"
    type "category"
    description "The defined roles and responsibilities of humans in the context of decision-making and oversight of AI systems."
    community_id 9
  ]
  node [
    id 217
    label "video compression models"
    type "technology"
    description "AI models specifically designed to improve the efficiency of video data compression."
    community_id 9
  ]
  node [
    id 218
    label "human decision maker"
    type "person"
    description "A human decision maker is an individual who makes decisions, potentially using AI systems as a supplementary opinion."
    community_id 9
  ]
  node [
    id 219
    label "cognitive biases"
    type "risk"
    description "Cognitive biases are systematic patterns of deviation from norm or rationality in judgment, which can affect decision-making processes in AI systems."
    community_id 9
  ]
  node [
    id 220
    label "standards, guidelines, best practices, methodologies, and tools"
    type "category"
    description "A collection of existing resources that help manage AI risks and foster awareness in the field."
    community_id 11
  ]
  node [
    id 221
    label "stakeholders"
    type "person"
    description "Individuals or groups involved in implementing AI risk management and learning from the framework."
    community_id 11
  ]
  node [
    id 222
    label "NIST.AI.100-1"
    type "document"
    description "A publication related to the AI RMF, available for free online."
    community_id 11
  ]
  node [
    id 223
    label "AI lifecycle stages"
  ]
  node [
    id 224
    label "society"
  ]
  node [
    id 225
    label "individuals and communities"
  ]
  node [
    id 226
    label "GOVERN"
  ]
  node [
    id 227
    label "MAP"
  ]
  node [
    id 228
    label "MEASURE"
  ]
  node [
    id 229
    label "MANAGE"
  ]
  node [
    id 230
    label "organization developing the AI system"
  ]
  node [
    id 231
    label "AI products or services"
  ]
  node [
    id 232
    label "risk management efforts"
  ]
  node [
    id 233
    label "risk measurement challenge"
  ]
  node [
    id 234
    label "methods"
  ]
  node [
    id 235
    label "AI lifecycle activities"
  ]
  node [
    id 236
    label "OECD framework"
  ]
  node [
    id 237
    label "subject matter experts"
  ]
  node [
    id 238
    label "validation"
  ]
  node [
    id 239
    label "reliability"
  ]
  node [
    id 240
    label "AI Lifecycle"
  ]
  node [
    id 241
    label "Privacy"
  ]
  node [
    id 242
    label "system design"
  ]
  node [
    id 243
    label "third-party software"
  ]
  node [
    id 244
    label "third-party entities"
  ]
  node [
    id 245
    label "high-risk systems"
  ]
  node [
    id 246
    label "AI system performance and trustworthiness"
  ]
  node [
    id 247
    label "human oversight processes"
  ]
  node [
    id 248
    label "AI system components"
  ]
  node [
    id 249
    label "evaluations involving human subjects"
  ]
  node [
    id 250
    label "AI Actors"
  ]
  node [
    id 251
    label "End users"
  ]
  edge [
    source 0
    target 1
    key 0
    type "includes"
    description "NIST AI 100-1 includes the Artificial Intelligence Risk Management Framework (AI RMF 1.0)."
  ]
  edge [
    source 0
    target 2
    key 0
    type "published_by"
    description "NIST AI 100-1 is published by the U.S. Department of Commerce."
  ]
  edge [
    source 0
    target 12
    key 0
    type "published_by"
    description "NIST AI 100-1 outlines and publishes the AI RMF 1.0 framework for managing AI risks."
  ]
  edge [
    source 0
    target 12
    key 1
    type "composed_of"
    description "NIST AI 100-1 includes the AI RMF 1.0 framework as part of its guidelines for AI risk management."
  ]
  edge [
    source 0
    target 12
    key 2
    type "provides"
    description "NIST AI 100-1 provides guidelines and standards that inform the implementation of the AI RMF 1.0."
  ]
  edge [
    source 0
    target 12
    key 3
    type "includes"
    description "Includes the AI Risk Management Framework 1.0 as part of its content."
  ]
  edge [
    source 0
    target 12
    key 4
    type "aligned_with"
    description "NIST AI 100-1 aligns with the principles and framework of AI RMF 1.0 for effective risk management."
  ]
  edge [
    source 0
    target 120
    key 0
    type "includes"
    description "NIST AI 100-1 includes references to NIST Special Publication 1270 for further information on bias."
  ]
  edge [
    source 0
    target 175
    key 0
    type "includes"
    description "NIST AI 100-1 includes the MANAGE 3 function for managing AI risks and benefits."
  ]
  edge [
    source 0
    target 178
    key 0
    type "includes"
    description "NIST AI 100-1 includes the MANAGE 4 function for documenting and monitoring risk treatments."
  ]
  edge [
    source 0
    target 202
    key 0
    type "published_by"
    description "NIST AI 100-1 is a document published by NIST related to the AI RMF."
  ]
  edge [
    source 2
    target 4
    key 0
    type "manages"
    description "The U.S. Department of Commerce manages the National Institute of Standards and Technology."
  ]
  edge [
    source 3
    target 2
    key 0
    type "directed_by"
    description "Gina M. Raimondo is the Secretary directing the U.S. Department of Commerce."
  ]
  edge [
    source 5
    target 4
    key 0
    type "directed_by"
    description "Laurie E. Locascio is the Director of the National Institute of Standards and Technology."
  ]
  edge [
    source 6
    target 7
    key 0
    type "published_by"
    description "The AI RMF Playbook is published by NIST."
  ]
  edge [
    source 6
    target 8
    key 0
    type "includes"
    description "The AI RMF Playbook includes a Version Control Table to track changes."
  ]
  edge [
    source 6
    target 10
    key 0
    type "subdivided_into"
    description "The AI RMF Playbook is subdivided into sections, including Foundational Information."
  ]
  edge [
    source 6
    target 11
    key 0
    type "subdivided_into"
    description "The AI RMF Playbook is subdivided into sections, including Core and Profiles."
  ]
  edge [
    source 7
    target 236
    key 0
    type "updated_by"
    description "NIST modified the OECD framework to emphasize TEVV processes in the AI lifecycle."
  ]
  edge [
    source 7
    target 12
    key 0
    type "develops"
    description "NIST develops the AI RMF 1.0 framework to assist organizations in managing AI risks."
  ]
  edge [
    source 7
    target 125
    key 0
    type "collaborates_with"
    description "NIST collaborates with the AI community to evaluate the effectiveness of the AI RMF."
  ]
  edge [
    source 9
    target 6
    key 0
    type "supports"
    description "The category of AI Risks and Trustworthiness supports the overall framework outlined in the AI RMF Playbook."
  ]
  edge [
    source 9
    target 12
    key 0
    type "aligned_with"
    description "AI Risks and Trustworthiness aligns with the principles outlined in the AI RMF 1.0."
  ]
  edge [
    source 12
    target 7
    key 0
    type "published_by"
    description "The AI RMF 1.0 document is published by NIST."
  ]
  edge [
    source 12
    target 7
    key 1
    type "develops"
    description "NIST develops the AI RMF 1.0 framework to guide AI risk management."
  ]
  edge [
    source 12
    target 40
    key 0
    type "supports"
    description "The AI RMF 1.0 supports the development of the AI Risk Management Framework Roadmap."
  ]
  edge [
    source 12
    target 41
    key 0
    type "infused_throughout"
    description "The principles of ISO 31000:2018 are infused throughout the AI RMF 1.0 framework."
  ]
  edge [
    source 12
    target 27
    key 0
    type "supports"
    description "The AI RMF 1.0 framework supports the responsible management of risks associated with AI systems through structured guidelines."
  ]
  edge [
    source 12
    target 58
    key 0
    type "supports"
    description "The AI RMF supports the prioritization of risk tolerance in AI systems."
  ]
  edge [
    source 12
    target 64
    key 0
    type "supports"
    description "The AI RMF 1.0 supports the development of a risk management culture within organizations by providing guidelines for risk assessment."
  ]
  edge [
    source 12
    target 67
    key 0
    type "includes"
    description "AI RMF 1.0 includes the concept of residual risk, emphasizing its importance in understanding the impacts on end users."
  ]
  edge [
    source 12
    target 172
    key 0
    type "supports"
    description "The AI RMF 1.0 supports the management of AI risks by providing a structured framework for integration into enterprise risk management."
  ]
  edge [
    source 12
    target 21
    key 0
    type "includes"
    description "The AI RMF 1.0 includes diverse AI actors necessary for effective risk management."
  ]
  edge [
    source 12
    target 21
    key 1
    type "applicable_to"
    description "The AI RMF 1.0 framework is applicable to AI actors involved in the development and deployment of AI systems."
  ]
  edge [
    source 12
    target 81
    key 0
    type "supports"
    description "AI RMF 1.0 provides guidance for achieving trustworthy AI."
  ]
  edge [
    source 12
    target 104
    key 0
    type "supports"
    description "AI RMF 1.0 supports the development of AI safety risk management approaches."
  ]
  edge [
    source 12
    target 118
    key 0
    type "aligned_with"
    description "AI RMF 1.0 is aligned with the principles of fairness in AI, emphasizing the need to manage bias."
  ]
  edge [
    source 12
    target 121
    key 0
    type "identifies"
    description "AI RMF 1.0 identifies systemic bias as a major category of AI bias."
  ]
  edge [
    source 12
    target 122
    key 0
    type "identifies"
    description "AI RMF 1.0 identifies computational and statistical bias as a major category of AI bias."
  ]
  edge [
    source 12
    target 123
    key 0
    type "identifies"
    description "AI RMF 1.0 identifies human-cognitive bias as a major category of AI bias."
  ]
  edge [
    source 12
    target 125
    key 0
    type "supports"
    description "The AI RMF 1.0 framework supports the AI community by providing guidelines for risk management."
  ]
  edge [
    source 12
    target 126
    key 0
    type "includes"
    description "The AI RMF 1.0 framework includes TEVV practices for evaluating AI systems."
  ]
  edge [
    source 12
    target 144
    key 0
    type "includes"
    description "The AI RMF 1.0 includes the MAP function, which is essential for establishing context and categorizing AI systems."
  ]
  edge [
    source 12
    target 0
    key 0
    type "published_by"
    description "The AI RMF 1.0 framework is published as part of the NIST AI 100-1 document."
  ]
  edge [
    source 13
    target 14
    key 0
    type "composed_of"
    description "The AI RMF Core includes the GOVERN function as one of its components."
  ]
  edge [
    source 13
    target 15
    key 0
    type "composed_of"
    description "The AI RMF Core includes the MAP function as one of its components."
  ]
  edge [
    source 13
    target 16
    key 0
    type "composed_of"
    description "The AI RMF Core includes the MEASURE function as one of its components."
  ]
  edge [
    source 13
    target 17
    key 0
    type "composed_of"
    description "The AI RMF Core includes the MANAGE function as one of its components."
  ]
  edge [
    source 13
    target 21
    key 0
    type "supports"
    description "The AI RMF Core supports the engagement with AI actors for diverse perspectives."
  ]
  edge [
    source 13
    target 127
    key 0
    type "identifies"
    description "The AI RMF Core identifies downstream risks associated with AI systems."
  ]
  edge [
    source 18
    target 12
    key 0
    type "aligned_with"
    description "AI Risks are addressed within the AI RMF 1.0 framework."
  ]
  edge [
    source 19
    target 13
    key 0
    type "includes"
    description "AI Actor Tasks are included in the discussions of the AI RMF Core."
  ]
  edge [
    source 20
    target 12
    key 0
    type "influences"
    description "The OECD Framework influences the design and understanding of AI systems within the AI RMF 1.0."
  ]
  edge [
    source 20
    target 26
    key 0
    type "aligned_with"
    description "The OECD framework is aligned with the principles outlined in the AI RMF."
  ]
  edge [
    source 21
    target 223
    key 0
    type "includes"
    description "AI actors are involved in various tasks throughout the AI lifecycle stages."
  ]
  edge [
    source 21
    target 27
    key 0
    type "manages"
    description "AI actors manage the risks associated with AI systems throughout their lifecycle, ensuring responsibilities are clearly defined."
  ]
  edge [
    source 21
    target 39
    key 0
    type "applicable_to"
    description "AI actors are involved in various stages of the AI lifecycle."
  ]
  edge [
    source 21
    target 39
    key 1
    type "operates_under"
    description "AI actors operate under the framework of the AI lifecycle."
  ]
  edge [
    source 21
    target 146
    key 0
    type "informed_by"
    description "The planning and implementation of the MANAGE function are informed by input from relevant AI actors."
  ]
  edge [
    source 21
    target 189
    key 0
    type "supports"
    description "AI actors support the TEVV framework by performing necessary tasks throughout the AI lifecycle."
  ]
  edge [
    source 22
    target 93
    key 0
    type "composed_of"
    description "Trustworthy AI systems are characterized by validity, reliability, accountability, and transparency."
  ]
  edge [
    source 23
    target 172
    key 0
    type "manages"
    description "AI risk management activities are designed to govern and manage risks associated with AI technologies."
  ]
  edge [
    source 24
    target 25
    key 0
    type "provides"
    description "NIST AI RMF 1.0 provides a framework for managing risks related to AI technologies."
  ]
  edge [
    source 24
    target 7
    key 0
    type "authored_by"
    description "The AI RMF 1.0 document is authored by NIST."
  ]
  edge [
    source 24
    target 6
    key 0
    type "includes"
    description "The AI RMF 1.0 includes additional resources provided in the AI RMF Playbook."
  ]
  edge [
    source 24
    target 37
    key 0
    type "aligned_with"
    description "The development of the AI RMF is aligned with the objectives of the National AI Initiative Act of 2020."
  ]
  edge [
    source 24
    target 38
    key 0
    type "aligned_with"
    description "The AI RMF is consistent with recommendations from the National Security Commission on Artificial Intelligence."
  ]
  edge [
    source 24
    target 226
    key 0
    type "composed_of"
    description "The AI RMF 1.0 framework is composed of the function GOVERN, among others."
  ]
  edge [
    source 24
    target 226
    key 1
    type "includes"
    description "The AI RMF framework includes the GOVERN function as part of its risk management process."
  ]
  edge [
    source 24
    target 227
    key 0
    type "composed_of"
    description "The AI RMF 1.0 framework includes the function MAP as part of its structure."
  ]
  edge [
    source 24
    target 228
    key 0
    type "composed_of"
    description "The AI RMF 1.0 framework includes the function MEASURE to evaluate AI risks."
  ]
  edge [
    source 24
    target 229
    key 0
    type "composed_of"
    description "The AI RMF 1.0 framework includes the function MANAGE for overseeing AI risk management."
  ]
  edge [
    source 24
    target 109
    key 0
    type "provides"
    description "The NIST AI RMF 1.0 document provides guidelines that promote transparency in AI systems."
  ]
  edge [
    source 24
    target 129
    key 0
    type "composed_of"
    description "The NIST AI RMF Playbook is an online companion resource that is part of the NIST AI RMF framework."
  ]
  edge [
    source 24
    target 129
    key 1
    type "published_by"
    description "The NIST AI RMF Playbook is published as part of the NIST AI RMF framework."
  ]
  edge [
    source 24
    target 39
    key 0
    type "applicable_to"
    description "The NIST AI RMF framework is applicable to various stages of the AI lifecycle."
  ]
  edge [
    source 24
    target 172
    key 0
    type "describes"
    description "The NIST AI RMF 1.0 document describes practices related to managing AI risks."
  ]
  edge [
    source 24
    target 21
    key 0
    type "published_by"
    description "NIST AI RMF 1.0 is a document published by NIST that serves as a guideline for AI actors."
  ]
  edge [
    source 25
    target 224
    key 0
    type "transforms"
    description "AI technologies have the potential to transform various aspects of society."
  ]
  edge [
    source 26
    target 27
    key 0
    type "describes"
    description "The AI RMF describes the nature and functionality of AI systems."
  ]
  edge [
    source 26
    target 27
    key 1
    type "supports"
    description "The AI RMF supports the management of risks associated with AI systems to enhance their trustworthiness."
  ]
  edge [
    source 26
    target 36
    key 0
    type "develops"
    description "The AI RMF is developed as a resource directed by the National Artificial Intelligence Initiative Act."
  ]
  edge [
    source 26
    target 21
    key 0
    type "supports"
    description "The AI RMF supports AI actors by providing frameworks for managing risks and enhancing the trustworthiness of AI systems."
  ]
  edge [
    source 26
    target 7
    key 0
    type "aligned_with"
    description "NIST aligns the AI RMF with applicable international standards and guidelines."
  ]
  edge [
    source 26
    target 42
    key 0
    type "develops"
    description "The AI RMF develops approaches to enhance risk management specifically for AI technologies."
  ]
  edge [
    source 26
    target 75
    key 0
    type "supports"
    description "The AI RMF supports the integration of TEVV tasks throughout the AI lifecycle."
  ]
  edge [
    source 26
    target 211
    key 0
    type "includes"
    description "The AI RMF includes the MAP, MEASURE, and MANAGE functions to address AI system risks."
  ]
  edge [
    source 26
    target 0
    key 0
    type "published_by"
    description "The AI RMF is published by NIST as part of their guidelines on AI risk management."
  ]
  edge [
    source 26
    target 60
    key 0
    type "supports"
    description "The AI RMF supports organizations' abilities to operate under applicable legal or regulatory regimes."
  ]
  edge [
    source 26
    target 220
    key 0
    type "fosters"
    description "The AI RMF fosters greater awareness of existing resources for managing AI risks."
  ]
  edge [
    source 26
    target 221
    key 0
    type "provides"
    description "The AI RMF provides a framework for stakeholders to learn from implementing AI risk management."
  ]
  edge [
    source 26
    target 97
    key 0
    type "applicable_to"
    description "The AI RMF is applicable to any AI technology and context-specific use cases."
  ]
  edge [
    source 27
    target 31
    key 0
    type "influenced_by"
    description "AI systems are influenced by societal dynamics and human behavior."
  ]
  edge [
    source 27
    target 32
    key 0
    type "creates_opportunities_for"
    description "AI systems can create opportunities for inequitable outcomes if not properly managed."
  ]
  edge [
    source 27
    target 45
    key 0
    type "illustrates"
    description "The complexities of AI systems illustrate the challenges in defining and measuring associated risks."
  ]
  edge [
    source 27
    target 60
    key 0
    type "applicable_to"
    description "AI systems are applicable to various organizations that may have different risk tolerances."
  ]
  edge [
    source 27
    target 64
    key 0
    type "applicable_to"
    description "AI systems are applicable to the risk management culture as they require specific risk assessments and management strategies."
  ]
  edge [
    source 27
    target 96
    key 0
    type "aligned_with"
    description "AI systems should comply with the safety requirements outlined in ISO/IEC TS 5723:2022 to avoid endangering human life and health."
  ]
  edge [
    source 27
    target 110
    key 0
    type "supports"
    description "AI systems benefit from transparency to enhance accountability and trustworthiness, particularly in relation to bias."
  ]
  edge [
    source 27
    target 111
    key 0
    type "supports"
    description "AI systems require accountability measures to ensure ethical and fair operation."
  ]
  edge [
    source 27
    target 124
    key 0
    type "supports"
    description "AI systems are closely associated with the concept of fairness in relation to bias."
  ]
  edge [
    source 27
    target 161
    key 0
    type "evaluates"
    description "AI systems are evaluated for trustworthy characteristics."
  ]
  edge [
    source 27
    target 101
    key 0
    type "evaluates"
    description "AI systems are evaluated regularly for safety risks."
  ]
  edge [
    source 27
    target 173
    key 0
    type "affects"
    description "AI systems can contribute to negative residual risks for downstream acquirers and end users."
  ]
  edge [
    source 27
    target 212
    key 0
    type "identifies"
    description "AI systems can exhibit harmful bias, which is a significant risk that needs to be managed."
  ]
  edge [
    source 27
    target 213
    key 0
    type "includes"
    description "Generative AI is a subset of AI systems that poses unique risks."
  ]
  edge [
    source 27
    target 214
    key 0
    type "identifies"
    description "AI systems are vulnerable to various machine learning attacks that can compromise security."
  ]
  edge [
    source 27
    target 215
    key 0
    type "identifies"
    description "AI systems may face risks from third-party AI technologies that are outside an organization's control."
  ]
  edge [
    source 27
    target 218
    key 0
    type "supports"
    description "AI systems can support human decision makers by providing additional opinions or insights."
  ]
  edge [
    source 28
    target 26
    key 0
    type "aligned_with"
    description "The OECD Recommendation on AI:2019 aligns with the principles outlined in the AI RMF."
  ]
  edge [
    source 29
    target 26
    key 0
    type "aligned_with"
    description "ISO/IEC 22989:2022 provides standards that align with the AI RMF."
  ]
  edge [
    source 30
    target 27
    key 0
    type "supports"
    description "AI risk management supports the responsible development and use of AI systems."
  ]
  edge [
    source 30
    target 33
    key 0
    type "supports"
    description "AI risk management drives responsible uses and practices in AI development."
  ]
  edge [
    source 30
    target 101
    key 0
    type "evaluates"
    description "AI risk management practices evaluate and prioritize safety risks to minimize potential harms."
  ]
  edge [
    source 33
    target 34
    key 0
    type "aligned_with"
    description "Responsible AI practices align with the principles of social responsibility outlined in ISO 26000:2010."
  ]
  edge [
    source 33
    target 35
    key 0
    type "aligned_with"
    description "Responsible AI is in accord with the professional responsibility defined by ISO/IEC TR 24368:2022."
  ]
  edge [
    source 36
    target 30
    key 0
    type "directed_by"
    description "The act directs the development of AI initiatives, including risk management practices."
  ]
  edge [
    source 37
    target 38
    key 0
    type "aligned_with"
    description "The National AI Initiative Act of 2020 aligns with the recommendations of the National Security Commission on Artificial Intelligence."
  ]
  edge [
    source 39
    target 55
    key 0
    type "supports"
    description "The AI lifecycle supports the development of trustworthy AI systems by outlining the necessary stages and responsibilities involved."
  ]
  edge [
    source 39
    target 92
    key 0
    type "supports"
    description "Enhancing contextual awareness in the AI lifecycle supports contextually sensitive evaluations."
  ]
  edge [
    source 39
    target 172
    key 0
    type "includes"
    description "The AI lifecycle includes various stages where AI risks need to be assessed."
  ]
  edge [
    source 42
    target 41
    key 0
    type "aligned_with"
    description "Risk management processes are aligned with the guidelines provided by ISO 31000:2018."
  ]
  edge [
    source 42
    target 43
    key 0
    type "provides"
    description "Risk management provides frameworks to understand and mitigate impacts on individuals, communities, and society."
  ]
  edge [
    source 42
    target 111
    key 0
    type "fosters"
    description "Risk management practices help foster accountability in the deployment of AI systems."
  ]
  edge [
    source 44
    target 45
    key 0
    type "contributes_to"
    description "Third-party resources contribute to the challenges faced in measuring AI risks effectively."
  ]
  edge [
    source 46
    target 47
    key 0
    type "aligned_with"
    description "The AI system's risk metrics may not align with those used by organizations deploying the system."
  ]
  edge [
    source 46
    target 101
    key 0
    type "evaluates"
    description "The AI system is evaluated for safety risks as identified in the MAP function."
  ]
  edge [
    source 46
    target 167
    key 0
    type "evaluates"
    description "The privacy risk of the AI system is examined and documented."
  ]
  edge [
    source 46
    target 168
    key 0
    type "evaluates"
    description "Fairness and bias associated with the AI system are evaluated and results are documented."
  ]
  edge [
    source 46
    target 169
    key 0
    type "assesses"
    description "The environmental impact of AI model training and management activities is assessed and documented."
  ]
  edge [
    source 49
    target 231
    key 0
    type "integrated_into"
    description "Third-party data can be integrated into AI products or services, affecting their risk profile."
  ]
  edge [
    source 50
    target 232
    key 0
    type "supports"
    description "Identifying and tracking emergent risks enhances organizations' risk management efforts."
  ]
  edge [
    source 51
    target 233
    key 0
    type "contributes_to"
    description "The lack of reliable metrics contributes to challenges in measuring risk and trustworthiness in AI."
  ]
  edge [
    source 52
    target 48
    key 0
    type "applicable_to"
    description "Methodologies for measuring impacts on a population are applicable to understanding AI harms."
  ]
  edge [
    source 53
    target 54
    key 0
    type "contributes_to"
    description "AI developers contribute to the deployment of AI systems by providing pre-trained models, which are then utilized by AI deployers."
  ]
  edge [
    source 53
    target 93
    key 0
    type "perceives"
    description "AI developers may interpret trustworthiness characteristics differently based on their role in the AI lifecycle."
  ]
  edge [
    source 54
    target 93
    key 0
    type "perceives"
    description "AI deployers assess trustworthiness characteristics based on the operational context of the AI system."
  ]
  edge [
    source 56
    target 42
    key 0
    type "identifies"
    description "Inscrutability identifies challenges in risk management for AI systems due to their opaque nature and limited explainability."
  ]
  edge [
    source 57
    target 42
    key 0
    type "provides"
    description "The human baseline provides a framework for comparing AI systems against human performance in decision-making tasks."
  ]
  edge [
    source 58
    target 59
    key 0
    type "aligned_with"
    description "Risk tolerance is influenced by guidelines established in ISO GUIDE 73."
  ]
  edge [
    source 59
    target 67
    key 0
    type "defines"
    description "ISO GUIDE 73 defines residual risk and its implications for risk management practices."
  ]
  edge [
    source 60
    target 87
    key 0
    type "manages"
    description "Organizations manage the characteristics of AI trustworthiness while facing tradeoffs."
  ]
  edge [
    source 61
    target 58
    key 0
    type "influences"
    description "Policies and norms established by organizations influence their risk tolerances."
  ]
  edge [
    source 62
    target 12
    key 0
    type "develops"
    description "The risk management framework is developed to augment existing practices like the AI RMF."
  ]
  edge [
    source 63
    target 234
    key 0
    type "contributes_to"
    description "Civil society contributes to the development of methods for harm/cost-benefit tradeoffs in AI."
  ]
  edge [
    source 65
    target 66
    key 0
    type "aligned_with"
    description "Risk criteria are aligned with the concept of risk tolerance, helping organizations define acceptable levels of risk."
  ]
  edge [
    source 66
    target 134
    key 0
    type "applicable_to"
    description "The risk tolerance of an organization is applicable to the activities outlined in the GOVERN function."
  ]
  edge [
    source 68
    target 27
    key 0
    type "affected_by"
    description "End users are affected by the risks associated with AI systems, particularly in terms of potential negative impacts."
  ]
  edge [
    source 68
    target 30
    key 0
    type "contributes_to"
    description "End users contribute to AI risk management by sharing their experiences and insights."
  ]
  edge [
    source 71
    target 172
    key 0
    type "faces"
    description "Small to medium-sized organizations face unique challenges in managing AI risks due to their limited resources."
  ]
  edge [
    source 72
    target 172
    key 0
    type "manages"
    description "Large organizations typically have more resources to manage AI risks effectively compared to smaller organizations."
  ]
  edge [
    source 73
    target 21
    key 0
    type "defines"
    description "OECD defines AI actors as those involved in the AI system lifecycle."
  ]
  edge [
    source 73
    target 235
    key 0
    type "develops"
    description "The OECD developed a framework for classifying AI lifecycle activities according to socio-technical dimensions."
  ]
  edge [
    source 74
    target 39
    key 0
    type "infused_throughout"
    description "TEVV processes are integrated throughout the AI lifecycle to ensure effective risk management."
  ]
  edge [
    source 74
    target 145
    key 0
    type "composed_of"
    description "TEVV processes are composed of methodologies that are part of the MEASURE function."
  ]
  edge [
    source 75
    target 39
    key 0
    type "infused_throughout"
    description "TEVV tasks are integrated throughout the AI lifecycle to manage risks effectively."
  ]
  edge [
    source 75
    target 21
    key 0
    type "includes"
    description "TEVV tasks involve AI actors who ensure the reliability of AI systems throughout their lifecycle."
  ]
  edge [
    source 76
    target 21
    key 0
    type "includes"
    description "The People &#38; Planet dimension includes AI actors who inform the primary audience regarding societal impacts."
  ]
  edge [
    source 77
    target 78
    key 0
    type "supports"
    description "The Plan and Design function supports the various stages of the AI system lifecycle."
  ]
  edge [
    source 79
    target 30
    key 0
    type "contributes_to"
    description "Environmental groups contribute to AI risk management by providing context and understanding of potential impacts."
  ]
  edge [
    source 80
    target 30
    key 0
    type "contributes_to"
    description "Civil society organizations contribute to AI risk management by offering norms and guidance."
  ]
  edge [
    source 81
    target 82
    key 0
    type "includes"
    description "Trustworthy AI encompasses various characteristics that define its trustworthiness."
  ]
  edge [
    source 82
    target 83
    key 0
    type "reflects"
    description "AI trustworthiness characteristics are influenced by social and organizational behavior."
  ]
  edge [
    source 82
    target 84
    key 0
    type "applicable_to"
    description "Datasets used by AI systems are relevant to the evaluation of AI trustworthiness characteristics."
  ]
  edge [
    source 82
    target 85
    key 0
    type "influences"
    description "The selection of AI models and algorithms affects the trustworthiness characteristics of AI systems."
  ]
  edge [
    source 84
    target 27
    key 0
    type "used_to_train"
    description "Datasets are used to train AI systems, but may become outdated or detached from their original context."
  ]
  edge [
    source 86
    target 82
    key 0
    type "contributes_to"
    description "Human judgment is essential in determining the metrics related to AI trustworthiness characteristics."
  ]
  edge [
    source 88
    target 70
    key 0
    type "tradeoff"
    description "There is a tradeoff between optimizing for interpretability and achieving privacy in AI systems."
  ]
  edge [
    source 88
    target 27
    key 0
    type "contributes_to"
    description "Interpretability helps users understand the meaning of AI systems' outputs in their functional context."
  ]
  edge [
    source 89
    target 88
    key 0
    type "tradeoff"
    description "A tradeoff exists between predictive accuracy and interpretability in certain scenarios."
  ]
  edge [
    source 90
    target 89
    key 0
    type "affects"
    description "Data sparsity can negatively affect predictive accuracy when using privacy-enhancing techniques."
  ]
  edge [
    source 93
    target 39
    key 0
    type "influences"
    description "Trustworthiness characteristics influence the evaluation and management of AI systems throughout the AI lifecycle."
  ]
  edge [
    source 94
    target 93
    key 0
    type "perceives"
    description "AI designers may have a different perception of trustworthiness characteristics compared to other AI actors."
  ]
  edge [
    source 95
    target 238
    key 0
    type "provides"
    description "ISO 9000:2015 provides guidelines for validating the requirements for specific intended uses of AI systems."
  ]
  edge [
    source 96
    target 239
    key 0
    type "defines"
    description "ISO/IEC TS 5723:2022 defines reliability as the ability of a system or product to perform as required without failure."
  ]
  edge [
    source 96
    target 99
    key 0
    type "defines"
    description "Defines accuracy as the closeness of results to true values."
  ]
  edge [
    source 96
    target 100
    key 0
    type "defines"
    description "Defines robustness as the ability to maintain performance under various circumstances."
  ]
  edge [
    source 96
    target 104
    key 0
    type "aligned_with"
    description "ISO/IEC TS 5723:2022 provides guidelines that align with AI safety risk management approaches."
  ]
  edge [
    source 97
    target 98
    key 0
    type "creates_opportunities_for"
    description "The deployment of AI technology can create opportunities for negative AI risks if not managed properly."
  ]
  edge [
    source 97
    target 158
    key 0
    type "includes"
    description "AI technology includes the use of third-party software and data."
  ]
  edge [
    source 99
    target 27
    key 0
    type "contributes_to"
    description "Contributes to the validity and trustworthiness of AI systems."
  ]
  edge [
    source 100
    target 27
    key 0
    type "contributes_to"
    description "Contributes to appropriate system functionality in a broad set of conditions."
  ]
  edge [
    source 102
    target 104
    key 0
    type "applicable_to"
    description "The NIST Cybersecurity Framework is applicable to AI safety risk management approaches."
  ]
  edge [
    source 102
    target 26
    key 0
    type "aligned_with"
    description "The NIST Cybersecurity Framework aligns with the AI RMF in addressing security and privacy considerations."
  ]
  edge [
    source 103
    target 104
    key 0
    type "applicable_to"
    description "The NIST Risk Management Framework is applicable to AI safety risk management approaches."
  ]
  edge [
    source 103
    target 26
    key 0
    type "aligned_with"
    description "The NIST Risk Management Framework provides a structured approach that complements the AI RMF."
  ]
  edge [
    source 105
    target 104
    key 0
    type "includes"
    description "Security and resilience are included as key considerations in AI safety risk management approaches."
  ]
  edge [
    source 106
    target 107
    key 0
    type "aligned_with"
    description "Resilience is a component of security, which also includes additional protocols."
  ]
  edge [
    source 108
    target 109
    key 0
    type "supports"
    description "Accountability in AI systems is supported by transparency."
  ]
  edge [
    source 109
    target 240
    key 0
    type "applicable_to"
    description "Transparency is relevant at various stages of the AI lifecycle."
  ]
  edge [
    source 112
    target 110
    key 0
    type "supports"
    description "Maintaining the provenance of training data supports transparency and accountability in AI systems."
  ]
  edge [
    source 113
    target 27
    key 0
    type "contributes_to"
    description "Explainability contributes to a better understanding of AI systems' operations and outputs."
  ]
  edge [
    source 114
    target 115
    key 0
    type "supports"
    description "Explainable AI frameworks support the development of interpretability in AI systems."
  ]
  edge [
    source 114
    target 109
    key 0
    type "supports"
    description "Explainable AI frameworks promote transparency in AI systems by clarifying decision-making processes."
  ]
  edge [
    source 116
    target 117
    key 0
    type "supports"
    description "The NIST Privacy Framework supports the use of privacy-enhancing technologies in AI system design."
  ]
  edge [
    source 116
    target 26
    key 0
    type "aligned_with"
    description "The NIST Privacy Framework aligns with the AI RMF to enhance privacy protections in AI systems."
  ]
  edge [
    source 118
    target 119
    key 0
    type "includes"
    description "Fairness in AI includes the management of harmful bias and discrimination."
  ]
  edge [
    source 120
    target 12
    key 0
    type "aligned_with"
    description "NIST Special Publication 1270 aligns with the AI RMF 1.0 framework for managing AI risks."
  ]
  edge [
    source 128
    target 13
    key 0
    type "contributes_to"
    description "A diverse team contributes to the AI RMF Core by providing varied perspectives."
  ]
  edge [
    source 129
    target 130
    key 0
    type "available_at"
    description "The NIST AI RMF Playbook is available through the NIST Trustworthy and Responsible AI Resource Center."
  ]
  edge [
    source 129
    target 144
    key 0
    type "includes"
    description "The NIST AI RMF Playbook includes the MAP function as part of its guidelines for managing AI risks."
  ]
  edge [
    source 131
    target 42
    key 0
    type "fosters"
    description "A strong organizational culture fosters effective risk management practices within an organization."
  ]
  edge [
    source 131
    target 42
    key 1
    type "aligned_with"
    description "Organizational culture is aligned with the principles of risk management as set by senior leadership."
  ]
  edge [
    source 132
    target 131
    key 0
    type "directed_by"
    description "Governing authorities direct the organizational culture by establishing overarching policies and values."
  ]
  edge [
    source 133
    target 42
    key 0
    type "influences"
    description "Senior leadership influences the approach to risk management within an organization by setting the tone and expectations."
  ]
  edge [
    source 134
    target 129
    key 0
    type "supports"
    description "The GOVERN function is supported by the practices described in the NIST AI RMF Playbook."
  ]
  edge [
    source 134
    target 135
    key 0
    type "supports"
    description "The GOVERN function supports the establishment of organizational risk priorities."
  ]
  edge [
    source 134
    target 172
    key 0
    type "manages"
    description "The GOVERN function manages AI risks through the implementation of policies and procedures."
  ]
  edge [
    source 134
    target 247
    key 0
    type "operates_under"
    description "Human oversight processes operate under the governance established by the GOVERN function."
  ]
  edge [
    source 134
    target 27
    key 0
    type "provides"
    description "The GOVERN function provides clarity on roles and responsibilities for humans overseeing AI systems."
  ]
  edge [
    source 134
    target 26
    key 0
    type "supports"
    description "The GOVERN function supports the AI RMF by clarifying roles and responsibilities in AI team configurations."
  ]
  edge [
    source 136
    target 135
    key 0
    type "contributes_to"
    description "AI risk management training contributes to achieving the organization's risk priorities."
  ]
  edge [
    source 137
    target 136
    key 0
    type "manages"
    description "Executive leadership manages the implementation of AI risk management training within the organization."
  ]
  edge [
    source 138
    target 21
    key 0
    type "supports"
    description "GOVERN 5 supports robust engagement with relevant AI actors."
  ]
  edge [
    source 139
    target 172
    key 0
    type "addresses"
    description "GOVERN 5.1 addresses AI risks by integrating feedback from external sources."
  ]
  edge [
    source 140
    target 242
    key 0
    type "contributes_to"
    description "GOVERN 5.2 contributes to system design by incorporating feedback from relevant AI actors."
  ]
  edge [
    source 141
    target 243
    key 0
    type "addresses"
    description "GOVERN 6 addresses AI risks and benefits arising from third-party software."
  ]
  edge [
    source 142
    target 244
    key 0
    type "addresses"
    description "GOVERN 6.1 addresses risks associated with third-party entities."
  ]
  edge [
    source 143
    target 245
    key 0
    type "provides"
    description "GOVERN 6.2 provides contingency processes for handling failures in high-risk systems."
  ]
  edge [
    source 144
    target 39
    key 0
    type "illustrates"
    description "The MAP function illustrates the interdependencies within the AI lifecycle."
  ]
  edge [
    source 144
    target 145
    key 0
    type "supports"
    description "The outcomes of the MAP function support the MEASURE function in assessing AI risks."
  ]
  edge [
    source 144
    target 146
    key 0
    type "supports"
    description "The MAP function provides foundational outcomes that inform the MANAGE function."
  ]
  edge [
    source 144
    target 172
    key 0
    type "identifies"
    description "The MAP function identifies AI risks to help organizations understand potential negative impacts."
  ]
  edge [
    source 144
    target 46
    key 0
    type "applicable_to"
    description "The MAP function is applicable to AI systems for ensuring context understanding and facilitating categorization and assessment."
  ]
  edge [
    source 144
    target 153
    key 0
    type "supports"
    description "The MAP function supports the identification and documentation of scientific integrity considerations."
  ]
  edge [
    source 144
    target 154
    key 0
    type "supports"
    description "The MAP function supports the identification and documentation of TEVV considerations."
  ]
  edge [
    source 144
    target 155
    key 0
    type "evaluates"
    description "The MAP function evaluates potential costs related to organizational risk tolerance in AI systems."
  ]
  edge [
    source 144
    target 21
    key 0
    type "includes"
    description "The MAP function includes practices for engaging with relevant AI actors."
  ]
  edge [
    source 144
    target 21
    key 1
    type "supports"
    description "The MAP function supports AI actors in assessing risks associated with AI systems."
  ]
  edge [
    source 144
    target 26
    key 0
    type "supports"
    description "The MAP function supports the AI RMF by suggesting documentation processes for AI system performance and trustworthiness."
  ]
  edge [
    source 145
    target 172
    key 0
    type "evaluates"
    description "The MEASURE function evaluates AI risks through various metrics and methodologies as part of an overall risk management strategy."
  ]
  edge [
    source 145
    target 172
    key 1
    type "supports"
    description "The MEASURE function supports the identification and analysis of AI risks."
  ]
  edge [
    source 145
    target 172
    key 2
    type "provides"
    description "The MEASURE function provides analytical outputs that inform the assessment of AI risks."
  ]
  edge [
    source 145
    target 146
    key 0
    type "informs"
    description "The MEASURE function informs the MANAGE function regarding AI risks."
  ]
  edge [
    source 145
    target 166
    key 0
    type "evaluates"
    description "The effectiveness of the employed TEVV metrics and processes in the MEASURE function are evaluated and documented."
  ]
  edge [
    source 145
    target 144
    key 0
    type "aligned_with"
    description "The MEASURE function includes evaluations based on risks identified in the MAP function."
  ]
  edge [
    source 145
    target 24
    key 0
    type "aligned_with"
    description "The MEASURE function is aligned with the guidelines provided in the NIST AI RMF 1.0 document."
  ]
  edge [
    source 146
    target 172
    key 0
    type "supports"
    description "The MANAGE function supports organizations in their efforts to mitigate AI risks."
  ]
  edge [
    source 146
    target 172
    key 1
    type "manages"
    description "The MANAGE function is responsible for managing AI risks based on assessments."
  ]
  edge [
    source 147
    target 148
    key 0
    type "engages_with"
    description "The internal team engages with external collaborators to incorporate diverse perspectives in AI development."
  ]
  edge [
    source 147
    target 68
    key 0
    type "engages_with"
    description "The internal team interacts with end users to understand their needs and impacts of AI systems."
  ]
  edge [
    source 147
    target 149
    key 0
    type "engages_with"
    description "The internal team may engage with potentially impacted communities based on the risk level of AI systems."
  ]
  edge [
    source 150
    target 144
    key 0
    type "utilizes"
    description "Framework users utilize the MAP function to inform decisions about AI system design and deployment."
  ]
  edge [
    source 150
    target 229
    key 0
    type "operates_under"
    description "Framework users apply the MANAGE function to effectively manage AI risks."
  ]
  edge [
    source 152
    target 151
    key 0
    type "evaluates"
    description "Interdisciplinary AI actors evaluate and document the organizational risk tolerances related to AI technologies."
  ]
  edge [
    source 156
    target 155
    key 0
    type "aligned_with"
    description "The categorization of AI systems is aligned with the organization's risk tolerance."
  ]
  edge [
    source 157
    target 246
    key 0
    type "supports"
    description "Proficiency in operation supports the performance and trustworthiness of AI systems."
  ]
  edge [
    source 159
    target 248
    key 0
    type "manages"
    description "Internal risk controls manage risks associated with components of AI systems."
  ]
  edge [
    source 160
    target 27
    key 0
    type "evaluates"
    description "The impacts of AI systems are evaluated to understand their effects on various stakeholders."
  ]
  edge [
    source 162
    target 172
    key 0
    type "supports"
    description "Metrics and measurement methodologies support the identification and assessment of AI risks."
  ]
  edge [
    source 163
    target 145
    key 0
    type "reflects"
    description "The effectiveness of the MEASURE function reflects the system trustworthiness of AI systems."
  ]
  edge [
    source 164
    target 145
    key 0
    type "contributes_to"
    description "The MEASURE function contributes to risk monitoring and response efforts by providing metrics and outcomes."
  ]
  edge [
    source 172
    target 225
    key 0
    type "negatively impacts"
    description "AI risks can negatively impact individuals, groups, organizations, and communities."
  ]
  edge [
    source 172
    target 69
    key 0
    type "aligned_with"
    description "AI risks are aligned with cybersecurity risks, as both involve critical concerns regarding data protection and system integrity."
  ]
  edge [
    source 172
    target 70
    key 0
    type "aligned_with"
    description "AI risks are aligned with privacy concerns, particularly regarding the use of data in AI systems."
  ]
  edge [
    source 172
    target 134
    key 0
    type "managed_by"
    description "AI risks are managed through the processes and practices established in the GOVERN function."
  ]
  edge [
    source 172
    target 170
    key 0
    type "informed_by"
    description "Domain experts provide insights that inform the identification and tracking of AI risks."
  ]
  edge [
    source 172
    target 68
    key 0
    type "provides"
    description "End users provide feedback on AI risks based on their interactions with the systems."
  ]
  edge [
    source 172
    target 171
    key 0
    type "supports"
    description "Affected communities are supported in reporting problems related to AI risks."
  ]
  edge [
    source 172
    target 144
    key 0
    type "identified_by"
    description "The MAP function identifies high-priority AI risks that need to be addressed."
  ]
  edge [
    source 172
    target 174
    key 0
    type "considered_with"
    description "Resources required to manage AI risks are considered alongside viable non-AI alternative systems."
  ]
  edge [
    source 175
    target 176
    key 0
    type "subdivided_into"
    description "MANAGE 3 is subdivided into MANAGE 3.1 for monitoring AI risks and benefits."
  ]
  edge [
    source 175
    target 177
    key 0
    type "subdivided_into"
    description "MANAGE 3 is subdivided into MANAGE 3.2 for monitoring pre-trained models."
  ]
  edge [
    source 178
    target 179
    key 0
    type "subdivided_into"
    description "MANAGE 4 is subdivided into MANAGE 4.1 for post-deployment monitoring plans."
  ]
  edge [
    source 178
    target 180
    key 0
    type "subdivided_into"
    description "MANAGE 4 is subdivided into MANAGE 4.2 for continual improvements in AI system updates."
  ]
  edge [
    source 178
    target 181
    key 0
    type "subdivided_into"
    description "MANAGE 4 is subdivided into MANAGE 4.3 for communication regarding incidents and errors."
  ]
  edge [
    source 182
    target 183
    key 0
    type "composed_of"
    description "AI RMF Profiles include AI RMF temporal profiles as part of their framework."
  ]
  edge [
    source 182
    target 0
    key 0
    type "published_by"
    description "AI RMF Profiles are associated with the NIST AI 100-1 document."
  ]
  edge [
    source 184
    target 185
    key 0
    type "compares"
    description "Comparing Current and Target Profiles likely reveals gaps to be addressed to meet AI risk management objectives."
  ]
  edge [
    source 186
    target 21
    key 0
    type "includes"
    description "AI Development includes various AI actors such as machine learning experts and data scientists."
  ]
  edge [
    source 187
    target 21
    key 0
    type "includes"
    description "AI Deployment includes AI actors like system integrators and end users who are crucial for effective deployment."
  ]
  edge [
    source 188
    target 21
    key 0
    type "includes"
    description "Operation and Monitoring includes AI actors such as system operators and compliance experts responsible for system assessment."
  ]
  edge [
    source 189
    target 27
    key 0
    type "applies_to"
    description "The TEVV framework applies to AI systems to ensure their reliability and compliance."
  ]
  edge [
    source 190
    target 27
    key 0
    type "evaluates"
    description "Compliance experts evaluate AI systems to ensure they meet legal and ethical standards."
  ]
  edge [
    source 191
    target 39
    key 0
    type "infused_throughout"
    description "Human Factors are integrated throughout the AI lifecycle to enhance user experience and system design."
  ]
  edge [
    source 192
    target 27
    key 0
    type "manages"
    description "Organizational management oversees the implementation and operation of AI systems within organizations."
  ]
  edge [
    source 193
    target 21
    key 0
    type "supports"
    description "Human factors professionals provide support to AI actors by informing user experience design and evaluation."
  ]
  edge [
    source 194
    target 195
    key 0
    type "contributes_to"
    description "Domain experts contribute essential guidance for AI impact assessment tasks."
  ]
  edge [
    source 195
    target 21
    key 0
    type "includes"
    description "AI actors such as impact assessors and evaluators are included in AI impact assessment tasks."
  ]
  edge [
    source 196
    target 21
    key 0
    type "managed_by"
    description "Procurement tasks are managed by AI actors with financial, legal, or policy authority."
  ]
  edge [
    source 197
    target 21
    key 0
    type "operates_under"
    description "Governance and oversight tasks operate under the authority of AI actors responsible for organizational management."
  ]
  edge [
    source 198
    target 251
    key 0
    type "provides"
    description "Third-party entities provide technologies and services that end users utilize in AI systems."
  ]
  edge [
    source 199
    target 27
    key 0
    type "impacts"
    description "Affected individuals and communities are impacted by the decisions made based on AI systems."
  ]
  edge [
    source 200
    target 172
    key 0
    type "provides"
    description "Other AI actors provide guidance for managing AI risks."
  ]
  edge [
    source 201
    target 25
    key 0
    type "experiences"
    description "The general public experiences both positive and negative impacts of AI technologies."
  ]
  edge [
    source 203
    target 204
    key 0
    type "compared_to"
    description "AI-based technology presents new risks compared to traditional software."
  ]
  edge [
    source 205
    target 206
    key 0
    type "includes"
    description "Pre-trained models are often utilized in transfer learning to enhance model performance."
  ]
  edge [
    source 206
    target 27
    key 0
    type "methodology"
    description "Transfer learning is a methodology that can be applied to enhance the capabilities of AI systems."
  ]
  edge [
    source 207
    target 203
    key 0
    type "affects"
    description "Data quality issues can negatively impact the trustworthiness of AI-based technology."
  ]
  edge [
    source 208
    target 27
    key 0
    type "applicable_to"
    description "Privacy and cybersecurity risk management considerations are applicable to the design and use of AI systems."
  ]
  edge [
    source 209
    target 27
    key 0
    type "includes"
    description "Enterprise risk management includes considerations for managing risks associated with AI systems."
  ]
  edge [
    source 210
    target 26
    key 0
    type "aligned_with"
    description "The Secure Software Development Framework shares principles that can inform the AI RMF."
  ]
  edge [
    source 215
    target 27
    key 0
    type "risk"
    description "Third-party AI technologies may introduce risks when integrated into an organization's AI systems."
  ]
  edge [
    source 216
    target 27
    key 0
    type "evaluates"
    description "Human roles and responsibilities are evaluated to ensure effective oversight of AI systems."
  ]
  edge [
    source 217
    target 27
    key 0
    type "function"
    description "Video compression models function as a specific application of AI systems that may not require human oversight."
  ]
  edge [
    source 219
    target 27
    key 0
    type "influences"
    description "Cognitive biases can influence the design and decision-making processes within AI systems."
  ]
  edge [
    source 222
    target 26
    key 0
    type "published_by"
    description "The document NIST.AI.100-1 is a publication related to the AI RMF."
  ]
  edge [
    source 226
    target 227
    key 0
    type "supports"
    description "After instituting outcomes in GOVERN, users typically start with the MAP function."
  ]
  edge [
    source 226
    target 12
    key 0
    type "supports"
    description "The GOVERN function supports the implementation of AI RMF 1.0 by integrating governance into AI risk management practices."
  ]
  edge [
    source 226
    target 27
    key 0
    type "applicable_to"
    description "The GOVERN function is applicable to AI systems, ensuring that risk management practices are implemented throughout their lifecycle."
  ]
  edge [
    source 227
    target 228
    key 0
    type "fosters"
    description "The MAP function fosters the subsequent MEASURE function in the AI RMF process."
  ]
  edge [
    source 228
    target 229
    key 0
    type "fosters"
    description "The MEASURE function fosters the ongoing MANAGE function in the AI RMF process."
  ]
  edge [
    source 229
    target 226
    key 0
    type "aligned_with"
    description "The MANAGE function is defined by the parameters set in the GOVERN function."
  ]
  edge [
    source 229
    target 227
    key 0
    type "supports"
    description "The MAP function provides analytical output that supports the prioritization and management of AI risks in the MANAGE function."
  ]
  edge [
    source 229
    target 228
    key 0
    type "supports"
    description "The MEASURE function contributes to the assessment of AI risks, which is essential for the MANAGE function."
  ]
  edge [
    source 230
    target 48
    key 0
    type "operates_under"
    description "The organization developing the AI system may use specific methodologies for risk measurement."
  ]
  edge [
    source 237
    target 91
    key 0
    type "evaluates"
    description "Subject matter experts evaluate TEVV findings to align them with deployment conditions."
  ]
  edge [
    source 241
    target 114
    key 0
    type "aligned_with"
    description "Privacy norms align with the principles of explainable AI by emphasizing user autonomy and control over personal data."
  ]
  edge [
    source 249
    target 165
    key 0
    type "applicable_to"
    description "Evaluations involving human subjects must meet human subject protection requirements."
  ]
  edge [
    source 250
    target 198
    key 0
    type "supports"
    description "AI actors support the involvement of third-party entities in AI design and development tasks."
  ]
]
